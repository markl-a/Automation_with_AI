"""
Kaggle ç«¶è³½ AI åŠ©æ‰‹

é€™å€‹æ¨¡å¡Šæä¾›å®Œæ•´çš„ Kaggle ç«¶è³½è¼”åŠ©åŠŸèƒ½ï¼Œ
ä½¿ç”¨ AI åŠ é€Ÿæ•¸æ“šæ¢ç´¢ã€ç‰¹å¾µå·¥ç¨‹ã€æ¨¡å‹é¸æ“‡å’Œå„ªåŒ–ã€‚
"""

import sys
import os

# æ·»åŠ é …ç›®è·¯å¾‘
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

from ai_automation_framework.llm import OpenAIClient
from ai_automation_framework.agents import BaseAgent
import pandas as pd
import json


class KaggleDataAnalyst:
    """Kaggle æ•¸æ“šåˆ†æåŠ©æ‰‹ - ä½¿ç”¨ AI è¼”åŠ©åˆ†æ"""

    def __init__(self, api_key: str = None):
        """
        åˆå§‹åŒ– Kaggle åŠ©æ‰‹

        Args:
            api_key: OpenAI API keyï¼ˆå¯é¸ï¼Œå¾ç’°å¢ƒè®Šé‡è®€å–ï¼‰
        """
        self.client = OpenAIClient(api_key=api_key)
        self.agent = BaseAgent(
            name="DataScientist",
            system_message="""ä½ æ˜¯ä¸€å€‹ç¶“é©—è±å¯Œçš„ Kaggle æ•¸æ“šç§‘å­¸å®¶ã€‚
            ä½ æ“…é•·ï¼š
            1. æ•¸æ“šæ¢ç´¢å’Œå¯è¦–åŒ–
            2. ç‰¹å¾µå·¥ç¨‹
            3. æ¨¡å‹é¸æ“‡å’Œå„ªåŒ–
            4. é¿å…éæ“¬åˆ
            5. é›†æˆå­¸ç¿’ç­–ç•¥

            ä½ çš„å›ç­”è¦å¯¦ç”¨ã€å…·é«”ï¼Œä¸¦æä¾›å¯åŸ·è¡Œçš„ä»£ç¢¼ã€‚
            """
        )

    def analyze_dataset(self, df: pd.DataFrame, target_column: str = None) -> dict:
        """
        å…¨é¢åˆ†ææ•¸æ“šé›†

        Args:
            df: æ•¸æ“šæ¡†
            target_column: ç›®æ¨™åˆ—å

        Returns:
            åŒ…å«åˆ†æçµæœå’Œå»ºè­°çš„å­—å…¸
        """
        print("ğŸ” é–‹å§‹æ•¸æ“šåˆ†æ...")

        # åŸºç¤çµ±è¨ˆ
        summary = {
            "shape": df.shape,
            "columns": list(df.columns),
            "dtypes": df.dtypes.astype(str).to_dict(),
            "missing": df.isnull().sum().to_dict(),
            "memory_usage": f"{df.memory_usage(deep=True).sum() / 1024**2:.2f} MB"
        }

        # æ•¸å€¼åˆ—çµ±è¨ˆ
        numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns
        if len(numeric_cols) > 0:
            summary["numeric_stats"] = df[numeric_cols].describe().to_dict()

        # åˆ†é¡åˆ—çµ±è¨ˆ
        categorical_cols = df.select_dtypes(include=['object', 'category']).columns
        if len(categorical_cols) > 0:
            summary["categorical_stats"] = {
                col: {
                    "unique": df[col].nunique(),
                    "top_values": df[col].value_counts().head(5).to_dict()
                }
                for col in categorical_cols
            }

        # ç›®æ¨™è®Šé‡åˆ†æ
        if target_column and target_column in df.columns:
            summary["target_info"] = {
                "dtype": str(df[target_column].dtype),
                "nunique": df[target_column].nunique(),
                "distribution": df[target_column].value_counts().head(10).to_dict()
            }

        # AI åˆ†æ
        print("ğŸ¤– ä½¿ç”¨ AI æ·±åº¦åˆ†æ...")
        ai_analysis = self._get_ai_analysis(summary, target_column)

        return {
            "summary": summary,
            "ai_insights": ai_analysis
        }

    def _get_ai_analysis(self, summary: dict, target_column: str = None) -> str:
        """ä½¿ç”¨ AI åˆ†ææ•¸æ“šé›†ç‰¹å¾µ"""

        prompt = f"""
        è«‹åˆ†æä»¥ä¸‹ Kaggle æ•¸æ“šé›†ï¼š

        **åŸºæœ¬ä¿¡æ¯**ï¼š
        - å½¢ç‹€ï¼š{summary['shape']}
        - åˆ—æ•¸ï¼š{len(summary['columns'])}
        - å…§å­˜ä½¿ç”¨ï¼š{summary['memory_usage']}

        **ç¼ºå¤±å€¼**ï¼š
        {json.dumps(summary['missing'], indent=2)}

        **æ•¸æ“šé¡å‹**ï¼š
        {json.dumps(summary['dtypes'], indent=2)}

        {f"**ç›®æ¨™è®Šé‡**: {target_column}" if target_column else ""}
        {f"åˆ†å¸ƒ: {summary.get('target_info', {})}" if target_column else ""}

        è«‹æä¾›ï¼š
        1. **æ•¸æ“šè³ªé‡è©•ä¼°**ï¼ˆ0-10åˆ†ï¼‰åŠåŸå› 
        2. **ä¸»è¦å•é¡Œ**ï¼ˆåˆ—å‡º 3-5 å€‹ï¼‰
        3. **è™•ç†å»ºè­°**ï¼ˆé‡å°æ¯å€‹å•é¡Œï¼‰
        4. **ä¸‹ä¸€æ­¥è¡Œå‹•**ï¼ˆå„ªå…ˆç´šæ’åºï¼‰

        ä»¥æ¸…æ™°çš„ Markdown æ ¼å¼å›ç­”ã€‚
        """

        return self.agent.chat(prompt)

    def suggest_features(self, df: pd.DataFrame, target: str, top_n: int = 10) -> str:
        """
        AI å»ºè­°ç‰¹å¾µå·¥ç¨‹

        Args:
            df: æ•¸æ“šæ¡†
            target: ç›®æ¨™åˆ—
            top_n: è¿”å›å»ºè­°æ•¸é‡

        Returns:
            ç‰¹å¾µå·¥ç¨‹å»ºè­°ï¼ˆå«ä»£ç¢¼ï¼‰
        """
        print(f"ğŸ’¡ ç”Ÿæˆ {top_n} å€‹ç‰¹å¾µå·¥ç¨‹å»ºè­°...")

        # æº–å‚™åˆ—ä¿¡æ¯
        column_info = []
        for col in df.columns:
            if col != target:
                info = {
                    "name": col,
                    "dtype": str(df[col].dtype),
                    "nunique": df[col].nunique(),
                    "missing": df[col].isnull().sum(),
                    "sample": df[col].dropna().head(3).tolist() if not df[col].isnull().all() else []
                }
                column_info.append(info)

        prompt = f"""
        Kaggle ç‰¹å¾µå·¥ç¨‹ä»»å‹™ï¼š

        **ç›®æ¨™è®Šé‡**: {target}
        **é¡å‹**: {df[target].dtype}

        **ç¾æœ‰ç‰¹å¾µ**ï¼š
        {json.dumps(column_info[:20], indent=2)}  # é™åˆ¶é•·åº¦

        è«‹æä¾› {top_n} å€‹æœ€æœ‰æ½›åŠ›çš„ç‰¹å¾µå·¥ç¨‹å»ºè­°ï¼š

        å°æ–¼æ¯å€‹å»ºè­°ï¼Œæä¾›ï¼š
        1. **ç‰¹å¾µåç¨±**
        2. **å‰µå»ºåŸç†**ï¼ˆç‚ºä»€éº¼æœ‰ç”¨ï¼‰
        3. **Python ä»£ç¢¼**ï¼ˆå¯ç›´æ¥åŸ·è¡Œï¼‰
        4. **é æœŸæ•ˆæœ**

        å„ªå…ˆè€ƒæ…®ï¼š
        - ç‰¹å¾µäº¤äº’
        - èšåˆç‰¹å¾µ
        - æ™‚é–“ç‰¹å¾µï¼ˆå¦‚æœæœ‰ï¼‰
        - ç·¨ç¢¼æ–¹æ³•

        ä»¥ Python ä»£ç¢¼å¡Šçš„å½¢å¼è¼¸å‡ºï¼ŒåŒ…å«è©³ç´°è¨»é‡‹ã€‚
        """

        return self.agent.chat(prompt)

    def suggest_models(self, df: pd.DataFrame, target: str, problem_type: str = None) -> str:
        """
        AI å»ºè­°æ¨¡å‹é¸æ“‡

        Args:
            df: æ•¸æ“šæ¡†
            target: ç›®æ¨™åˆ—
            problem_type: å•é¡Œé¡å‹ï¼ˆ'classification' æˆ– 'regression'ï¼‰

        Returns:
            æ¨¡å‹å»ºè­°å’Œä»£ç¢¼
        """
        print("ğŸ¯ åˆ†æå•é¡Œä¸¦æ¨è–¦æ¨¡å‹...")

        # è‡ªå‹•åˆ¤æ–·å•é¡Œé¡å‹
        if problem_type is None:
            if df[target].dtype in ['int64', 'float64'] and df[target].nunique() > 20:
                problem_type = 'regression'
            else:
                problem_type = 'classification'

        prompt = f"""
        Kaggle æ¨¡å‹é¸æ“‡ä»»å‹™ï¼š

        **å•é¡Œé¡å‹**: {problem_type}
        **æ•¸æ“šé›†å¤§å°**: {df.shape}
        **ç‰¹å¾µæ•¸**: {df.shape[1] - 1}
        **ç›®æ¨™è®Šé‡å”¯ä¸€å€¼**: {df[target].nunique()}

        è«‹æ¨è–¦ 5 å€‹é©åˆçš„æ¨¡å‹ï¼ŒæŒ‰å„ªå…ˆç´šæ’åºï¼š

        å°æ–¼æ¯å€‹æ¨¡å‹ï¼š
        1. **æ¨¡å‹åç¨±**
        2. **ç‚ºä»€éº¼é©åˆ**ï¼ˆ3å€‹ç†ç”±ï¼‰
        3. **å„ªé»å’Œç¼ºé»**
        4. **åŸºç¤å¯¦ç¾ä»£ç¢¼**ï¼ˆå«åƒæ•¸ï¼‰
        5. **è¶…åƒæ•¸èª¿å„ªå»ºè­°**

        åŒ…æ‹¬ï¼š
        - å‚³çµ±æ¨¡å‹ï¼ˆå¦‚ XGBoost, LightGBMï¼‰
        - ç¥ç¶“ç¶²çµ¡ï¼ˆå¦‚æœé©ç”¨ï¼‰
        - é›†æˆæ–¹æ³•

        æä¾›å®Œæ•´çš„ Python ä»£ç¢¼ç¤ºä¾‹ã€‚
        """

        return self.agent.chat(prompt)

    def debug_error(self, error_message: str, code: str, context: str = "") -> str:
        """
        AI è¼”åŠ©èª¿è©¦éŒ¯èª¤

        Args:
            error_message: éŒ¯èª¤ä¿¡æ¯
            code: å‡ºéŒ¯çš„ä»£ç¢¼
            context: é¡å¤–ä¸Šä¸‹æ–‡

        Returns:
            è§£æ±ºæ–¹æ¡ˆ
        """
        print("ğŸ”§ AI æ­£åœ¨åˆ†æéŒ¯èª¤...")

        prompt = f"""
        Kaggle ç«¶è³½ä¸­é‡åˆ°éŒ¯èª¤ï¼Œè«‹å¹«åŠ©è§£æ±ºï¼š

        **éŒ¯èª¤ä¿¡æ¯**ï¼š
        ```
        {error_message}
        ```

        **ç›¸é—œä»£ç¢¼**ï¼š
        ```python
        {code}
        ```

        **é¡å¤–ä¸Šä¸‹æ–‡**ï¼š
        {context if context else "ç„¡"}

        è«‹æä¾›ï¼š
        1. **éŒ¯èª¤åŸå› **ï¼ˆè©³ç´°è§£é‡‹ï¼‰
        2. **ä¿®å¾©ä»£ç¢¼**ï¼ˆå®Œæ•´å¯ç”¨ï¼‰
        3. **é é˜²æªæ–½**ï¼ˆé¿å…é¡ä¼¼éŒ¯èª¤ï¼‰
        4. **æœ€ä½³å¯¦è¸**ï¼ˆç›¸é—œå»ºè­°ï¼‰

        ä»¥æ¸…æ™°çš„æ ¼å¼å›ç­”ï¼Œä»£ç¢¼è¦å®Œæ•´å¯åŸ·è¡Œã€‚
        """

        return self.agent.chat(prompt)

    def optimize_score(self, current_score: float, approach: str, leaderboard_top: float) -> str:
        """
        AI å»ºè­°æå‡åˆ†æ•¸

        Args:
            current_score: ç•¶å‰åˆ†æ•¸
            approach: ç•¶å‰æ–¹æ³•æè¿°
            leaderboard_top: æ’è¡Œæ¦œé ‚éƒ¨åˆ†æ•¸

        Returns:
            å„ªåŒ–å»ºè­°
        """
        print("ğŸ“ˆ ç”Ÿæˆåˆ†æ•¸æå‡å»ºè­°...")

        gap = leaderboard_top - current_score
        gap_percentage = (gap / leaderboard_top) * 100

        prompt = f"""
        Kaggle ç«¶è³½åˆ†æ•¸å„ªåŒ–ï¼š

        **ç•¶å‰ç‹€æ³**ï¼š
        - æˆ‘çš„åˆ†æ•¸ï¼š{current_score}
        - æ’è¡Œæ¦œç¬¬ä¸€ï¼š{leaderboard_top}
        - å·®è·ï¼š{gap:.4f} ({gap_percentage:.2f}%)

        **ç•¶å‰æ–¹æ³•**ï¼š
        {approach}

        è«‹æä¾›æå‡è¨ˆåŠƒï¼š

        **éšæ®µ 1ï¼šå¿«é€Ÿæå‡ï¼ˆ1-2å¤©ï¼‰**
        - å¯ä»¥ç«‹å³å˜—è©¦çš„ 3-5 å€‹æ–¹æ³•
        - é æœŸæå‡å¹…åº¦

        **éšæ®µ 2ï¼šç©©å®šå„ªåŒ–ï¼ˆ3-5å¤©ï¼‰**
        - æ›´æ·±å…¥çš„å„ªåŒ–æ–¹å‘
        - éœ€è¦çš„æ™‚é–“æŠ•å…¥

        **éšæ®µ 3ï¼šçªç ´ç“¶é ¸ï¼ˆå¦‚æœéœ€è¦ï¼‰**
        - å‰µæ–°æ€§æ–¹æ³•
        - é«˜ç´šæŠ€å·§

        æ¯å€‹å»ºè­°åŒ…å«ï¼š
        - å…·é«”è¡Œå‹•
        - å¯¦æ–½é›£åº¦ï¼ˆç°¡å–®/ä¸­ç­‰/å›°é›£ï¼‰
        - é æœŸæ•ˆæœ
        - ä»£ç¢¼ç¤ºä¾‹ï¼ˆå¦‚æœé©ç”¨ï¼‰

        å„ªå…ˆè€ƒæ…®æ€§åƒ¹æ¯”é«˜çš„æ–¹æ³•ã€‚
        """

        return self.agent.chat(prompt)

    def generate_submission_code(self, model_description: str) -> str:
        """
        AI ç”Ÿæˆæäº¤ä»£ç¢¼æ¨¡æ¿

        Args:
            model_description: æ¨¡å‹æè¿°

        Returns:
            æäº¤ä»£ç¢¼
        """
        print("ğŸ“ ç”Ÿæˆæäº¤ä»£ç¢¼...")

        prompt = f"""
        ç‚ºä»¥ä¸‹ Kaggle æ¨¡å‹ç”Ÿæˆå®Œæ•´çš„æäº¤ä»£ç¢¼ï¼š

        **æ¨¡å‹æè¿°**ï¼š
        {model_description}

        ç”ŸæˆåŒ…å«ä»¥ä¸‹éƒ¨åˆ†çš„å®Œæ•´ä»£ç¢¼ï¼š

        1. **å°å…¥åº«**
        2. **æ•¸æ“šåŠ è¼‰**
        3. **é è™•ç†**ï¼ˆèˆ‡è¨“ç·´æ™‚ä¸€è‡´ï¼‰
        4. **æ¨¡å‹åŠ è¼‰**
        5. **é æ¸¬**
        6. **ç”Ÿæˆæäº¤æ–‡ä»¶**ï¼ˆæ­£ç¢ºæ ¼å¼ï¼‰
        7. **é©—è­‰**ï¼ˆæª¢æŸ¥æ ¼å¼ã€ç¯„åœç­‰ï¼‰

        ä»£ç¢¼è¦æ±‚ï¼š
        - å®Œæ•´å¯åŸ·è¡Œ
        - åŒ…å«éŒ¯èª¤è™•ç†
        - æœ‰è©³ç´°è¨»é‡‹
        - ç¬¦åˆ Kaggle æäº¤è¦æ±‚

        ä»¥ Python ä»£ç¢¼å¡Šå½¢å¼è¼¸å‡ºã€‚
        """

        return self.agent.chat(prompt)


class KaggleWorkflow:
    """å®Œæ•´çš„ Kaggle å·¥ä½œæµç¨‹åŠ©æ‰‹"""

    def __init__(self):
        self.analyst = KaggleDataAnalyst()

    def quick_start(self, train_path: str, test_path: str, target: str):
        """
        Kaggle ç«¶è³½å¿«é€Ÿå•Ÿå‹•

        Args:
            train_path: è¨“ç·´æ•¸æ“šè·¯å¾‘
            test_path: æ¸¬è©¦æ•¸æ“šè·¯å¾‘
            target: ç›®æ¨™åˆ—å
        """
        print("=" * 60)
        print("ğŸš€ Kaggle ç«¶è³½å¿«é€Ÿå•Ÿå‹•")
        print("=" * 60)

        # åŠ è¼‰æ•¸æ“š
        print("\nğŸ“‚ åŠ è¼‰æ•¸æ“š...")
        train_df = pd.read_csv(train_path)
        test_df = pd.read_csv(test_path)
        print(f"è¨“ç·´é›†: {train_df.shape}, æ¸¬è©¦é›†: {test_df.shape}")

        # éšæ®µ 1: æ•¸æ“šåˆ†æ
        print("\n" + "=" * 60)
        print("éšæ®µ 1: æ•¸æ“šæ¢ç´¢å’Œåˆ†æ")
        print("=" * 60)
        analysis = self.analyst.analyze_dataset(train_df, target)
        print("\nğŸ“Š AI åˆ†æçµæœ:")
        print(analysis['ai_insights'])

        # éšæ®µ 2: ç‰¹å¾µå·¥ç¨‹å»ºè­°
        print("\n" + "=" * 60)
        print("éšæ®µ 2: ç‰¹å¾µå·¥ç¨‹å»ºè­°")
        print("=" * 60)
        features = self.analyst.suggest_features(train_df, target, top_n=5)
        print("\nğŸ’¡ ç‰¹å¾µå»ºè­°:")
        print(features)

        # éšæ®µ 3: æ¨¡å‹å»ºè­°
        print("\n" + "=" * 60)
        print("éšæ®µ 3: æ¨¡å‹é¸æ“‡")
        print("=" * 60)
        models = self.analyst.suggest_models(train_df, target)
        print("\nğŸ¯ æ¨¡å‹å»ºè­°:")
        print(models)

        # ç¸½çµ
        print("\n" + "=" * 60)
        print("âœ… å¿«é€Ÿå•Ÿå‹•å®Œæˆï¼")
        print("=" * 60)
        print("\nä¸‹ä¸€æ­¥ï¼š")
        print("1. å¯¦æ–½å»ºè­°çš„ç‰¹å¾µå·¥ç¨‹")
        print("2. è¨“ç·´æ¨è–¦çš„æ¨¡å‹")
        print("3. é©—è­‰å’Œå„ªåŒ–")
        print("4. ç”Ÿæˆæäº¤æ–‡ä»¶")

        return {
            "analysis": analysis,
            "features": features,
            "models": models
        }


def main():
    """
    ç¤ºä¾‹ç”¨æ³•
    """
    print("Kaggle AI åŠ©æ‰‹ç¤ºä¾‹\n")

    # æ–¹æ³• 1: åˆ†æç¾æœ‰æ•¸æ“š
    print("æ–¹æ³• 1: åˆ†ææ•¸æ“šé›†")
    print("-" * 40)

    # å‰µå»ºç¤ºä¾‹æ•¸æ“š
    sample_data = pd.DataFrame({
        'feature1': [1, 2, 3, 4, 5] * 20,
        'feature2': ['A', 'B', 'C', 'D', 'E'] * 20,
        'feature3': [10.5, 20.3, 30.1, 40.8, 50.2] * 20,
        'target': [0, 1, 0, 1, 0] * 20
    })

    analyst = KaggleDataAnalyst()

    # åˆ†ææ•¸æ“š
    analysis = analyst.analyze_dataset(sample_data, target_column='target')
    print("\nAI åˆ†æ:")
    print(analysis['ai_insights'])

    # æ–¹æ³• 2: ç²å–ç‰¹å¾µå»ºè­°
    print("\n\næ–¹æ³• 2: ç‰¹å¾µå·¥ç¨‹å»ºè­°")
    print("-" * 40)
    features = analyst.suggest_features(sample_data, 'target', top_n=3)
    print(features)

    # æ–¹æ³• 3: èª¿è©¦å¹«åŠ©
    print("\n\næ–¹æ³• 3: èª¿è©¦éŒ¯èª¤")
    print("-" * 40)
    solution = analyst.debug_error(
        error_message="ValueError: Input contains NaN",
        code="model.fit(X_train, y_train)",
        context="ä½¿ç”¨ XGBoost è¨“ç·´æ¨¡å‹æ™‚å‡ºéŒ¯"
    )
    print(solution)

    # æ–¹æ³• 4: å®Œæ•´å·¥ä½œæµï¼ˆå¦‚æœæœ‰çœŸå¯¦æ•¸æ“šï¼‰
    # workflow = KaggleWorkflow()
    # result = workflow.quick_start('train.csv', 'test.csv', 'target')


if __name__ == "__main__":
    # æª¢æŸ¥æ˜¯å¦é…ç½®äº† API key
    import os
    if not os.getenv('OPENAI_API_KEY'):
        print("âš ï¸  è­¦å‘Š: æœªæª¢æ¸¬åˆ° OPENAI_API_KEY ç’°å¢ƒè®Šé‡")
        print("è«‹è¨­ç½® API key å¾Œå†é‹è¡Œæ­¤è…³æœ¬")
        print("\nè¨­ç½®æ–¹æ³•:")
        print("export OPENAI_API_KEY='your-api-key-here'")
    else:
        main()
